{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshOdegai/Josh_DTSC3020_Fall2025/blob/main/Assignment_6_WebScraping_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_de5Eq4u-tR"
      },
      "source": [
        "# Assignment 6 (4 points) — Web Scraping\n",
        "\n",
        "In this assignment you will complete **two questions**. The **deadline is posted on Canvas**.\n"
      ],
      "id": "H_de5Eq4u-tR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHwamZMu-tX"
      },
      "source": [
        "## Assignment Guide (Read Me First)\n",
        "\n",
        "- This notebook provides an **Install Required Libraries** cell and a **Common Imports & Polite Headers** cell. Run them first.\n",
        "- Each question includes a **skeleton**. The skeleton is **not** a solution; it is a lightweight scaffold you may reuse.\n",
        "- Under each skeleton you will find a **“Write your answer here”** code cell. Implement your scraping, cleaning, and saving logic there.\n",
        "- When your code is complete, run the **Runner** cell to print a Top‑15 preview and save the CSV.\n",
        "- Expected outputs:\n",
        "  - **Q1:** `data_q1.csv` + Top‑15 sorted by the specified numeric column.\n",
        "  - **Q2:** `data_q2.csv` + Top‑15 sorted by `points`.\n"
      ],
      "id": "4PHwamZMu-tX"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I7DLq9nEu-tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0360432d-4573-42bb-e6cd-cf87b8761402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# 1) Install Required Libraries\n",
        "!pip -q install requests beautifulsoup4 lxml pandas\n",
        "print(\"Dependencies installed.\")\n"
      ],
      "id": "I7DLq9nEu-tZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug_A9RuPu-tb"
      },
      "source": [
        "### 2) Common Imports & Polite Headers"
      ],
      "id": "ug_A9RuPu-tb"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ov8pXh65u-tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903d3e59-178a-43d8-929a-2b66bee9f428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common helpers loaded.\n"
          ]
        }
      ],
      "source": [
        "# Common Imports & Polite Headers\n",
        "import re, sys, pandas as pd, requests\n",
        "from bs4 import BeautifulSoup\n",
        "HEADERS = {\"User-Agent\": (\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "    \"(KHTML, like Gecko) Chrome/122.0 Safari/537.36\")}\n",
        "def fetch_html(url: str, timeout: int = 20) -> str:\n",
        "    r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "def flatten_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = [\" \".join([str(x) for x in tup if str(x)!=\"nan\"]).strip()\n",
        "                      for tup in df.columns.values]\n",
        "    else:\n",
        "        df.columns = [str(c).strip() for c in df.columns]\n",
        "    return df\n",
        "print(\"Common helpers loaded.\")\n"
      ],
      "id": "Ov8pXh65u-tc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km0GO7zzu-td"
      },
      "source": [
        "## Question 1 — IBAN Country Codes (table)\n",
        "**URL:** https://www.iban.com/country-codes  \n",
        "**Extract at least:** `Country`, `Alpha-2`, `Alpha-3`, `Numeric` (≥4 cols; you may add more)  \n",
        "**Clean:** trim spaces; `Alpha-2/Alpha-3` → **UPPERCASE**; `Numeric` → **int** (nullable OK)  \n",
        "**Output:** write **`data_q1.csv`** and **print a Top-15** sorted by `Numeric` (desc, no charts)  \n",
        "**Deliverables:** notebook + `data_q1.csv` + short `README.md` (URL, steps, 1 limitation)\n",
        "\n",
        "**Tip:** You can use `pandas.read_html(html)` to read tables and then pick one with ≥3 columns.\n"
      ],
      "id": "km0GO7zzu-td"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q1_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q1 Skeleton (fill the TODOs) ---\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\n",
        "    TODO: implement with pd.read_html(html), pick a reasonable table, then flatten headers.\n",
        "    \"\"\"\n",
        "    tables = pd.read_html(html)\n",
        "    for table in tables:\n",
        "      if table.shape[1] >= 3:\n",
        "        return flatten_headers(table)\n",
        "    raise NotImplementedError(\"TODO: implement q1_read_table\")\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable), drop invalids.\n",
        "    TODO: implement cleaning steps.\n",
        "    \"\"\"\n",
        "    cols = {c.lower(): c for c in df.columns}  # case-insensitive\n",
        "    country_col = next((cols[k] for k in cols if \"country\" in k), None)\n",
        "    alpha2_col = next((cols[k] for k in cols if \"alpha-2\" in k or \"alpha 2\" in k), None)\n",
        "    alpha3_col = next((cols[k] for k in cols if \"alpha-3\" in k or \"alpha 3\" in k), None)\n",
        "    numeric_col = next((cols[k] for k in cols if \"numeric\" in k), None)\n",
        "\n",
        "    # Filter to needed columns (ignore extras if present)\n",
        "    keep = [c for c in [country_col, alpha2_col, alpha3_col, numeric_col] if c]\n",
        "    df = df[keep].copy()\n",
        "\n",
        "    # Normalized names\n",
        "    new_names = [\"Country\", \"Alpha-2\", \"Alpha-3\", \"Numeric\"]\n",
        "    df.columns = new_names[:len(df.columns)]\n",
        "\n",
        "    # Strip string whitespace where applicable\n",
        "    for col in [\"Country\", \"Alpha-2\", \"Alpha-3\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.strip()\n",
        "\n",
        "    # Uppercase ISO codes\n",
        "    if \"Alpha-2\" in df.columns:\n",
        "        df[\"Alpha-2\"] = df[\"Alpha-2\"].str.upper()\n",
        "    if \"Alpha-3\" in df.columns:\n",
        "        df[\"Alpha-3\"] = df[\"Alpha-3\"].str.upper()\n",
        "\n",
        "    # Convert Numeric → Int64 (nullable)\n",
        "    if \"Numeric\" in df.columns:\n",
        "        df[\"Numeric\"] = df[\"Numeric\"].astype(\"Int64\")\n",
        "\n",
        "    # Drop rows missing the two most essential fields\n",
        "    df = df.dropna(subset=[\"Country\", \"Alpha-2\"])\n",
        "\n",
        "    return df.reset_index(drop=True)\n",
        "    raise NotImplementedError(\"TODO: implement q1_clean\")\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top-N.\n",
        "    TODO: implement.\n",
        "    \"\"\"\n",
        "    df_sorted = df.dropna(subset=[\"Numeric\"]).sort_values(\n",
        "      by=\"Numeric\", ascending=False\n",
        "    )\n",
        "    return df_sorted.head(top).reset_index(drop=True)\n",
        "    raise NotImplementedError(\"TODO: implement q1_sort_top\")\n"
      ],
      "id": "q1_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q1_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94694690-8992-48d7-a250-14063842980a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Country Alpha-2 Alpha-3  Numeric\n",
            "0                                              Zambia      ZM     ZMB      894\n",
            "1                                               Yemen      YE     YEM      887\n",
            "2                                               Samoa      WS     WSM      882\n",
            "3                                   Wallis and Futuna      WF     WLF      876\n",
            "4                  Venezuela (Bolivarian Republic of)      VE     VEN      862\n",
            "5                                          Uzbekistan      UZ     UZB      860\n",
            "6                                             Uruguay      UY     URY      858\n",
            "7                                        Burkina Faso      BF     BFA      854\n",
            "8                               Virgin Islands (U.S.)      VI     VIR      850\n",
            "9                      United States of America (the)      US     USA      840\n",
            "10                       Tanzania, United Republic of      TZ     TZA      834\n",
            "11                                        Isle of Man      IM     IMN      833\n",
            "12                                             Jersey      JE     JEY      832\n",
            "13                                           Guernsey      GG     GGY      831\n",
            "14  United Kingdom of Great Britain and Northern I...      GB     GBR      826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3383860988.py:6: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  tables = pd.read_html(html)\n"
          ]
        }
      ],
      "source": [
        "# Q1 — Write your answer here\n",
        "URL = \"https://www.iban.com/country-codes\"\n",
        "\n",
        "\n",
        "html = fetch_html(URL)\n",
        "df_raw = q1_read_table(html)\n",
        "df_clean = q1_clean(df_raw)\n",
        "\n",
        "df_clean.to_csv(\"data_q1.csv\", index=False)\n",
        "\n",
        "print(q1_sort_top(df_clean, top=15))\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "q1_skeleton_answer"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmefu--_u-tg"
      },
      "source": [
        "## Question 2 — Hacker News (front page)\n",
        "**URL:** https://news.ycombinator.com/  \n",
        "**Extract at least:** `rank`, `title`, `link`, `points`, `comments` (user optional)  \n",
        "**Clean:** cast `points`/`comments`/`rank` → **int** (non-digits → 0), fill missing text fields  \n",
        "**Output:** write **`data_q2.csv`** and **print a Top-15** sorted by `points` (desc, no charts)  \n",
        "**Tip:** Each story is a `.athing` row; details (points/comments/user) are in the next `<tr>` with `.subtext`.\n"
      ],
      "id": "rmefu--_u-tg"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q2_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q2 Skeleton (fill the TODOs) ---\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into DataFrame columns:\n",
        "       rank, title, link, points, comments, user (optional).\n",
        "    TODO: implement with BeautifulSoup on '.athing' and its sibling '.subtext'.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    items = []\n",
        "\n",
        "    rows = soup.select(\"tr.athing\")\n",
        "    for row in rows:\n",
        "        rank_tag = row.select_one(\".rank\")\n",
        "\n",
        "        title_tag = row.select_one(\".titleline a\")\n",
        "        link = title_tag[\"href\"] if title_tag and title_tag.has_attr(\"href\") else \"\"\n",
        "\n",
        "        sub = row.find_next_sibling(\"tr\")\n",
        "        subtext = sub.select_one(\".subtext\") if sub else None\n",
        "\n",
        "        points_tag = subtext.select_one(\".score\") if subtext else None\n",
        "        user_tag = subtext.select_one(\".hnuser\") if subtext else None\n",
        "\n",
        "        comments_tag = None\n",
        "        if subtext:\n",
        "            links = subtext.find_all(\"a\")\n",
        "            if links:\n",
        "                comments_tag = links[-1]\n",
        "\n",
        "        items.append({\n",
        "            \"rank\": rank_tag.text.strip().replace(\".\", \"\") if rank_tag else \"\",\n",
        "            \"title\": title_tag.text.strip() if title_tag else \"\",\n",
        "            \"link\": link,\n",
        "            \"points\": points_tag.text.strip() if points_tag else \"\",\n",
        "            \"comments\": comments_tag.text.strip() if comments_tag else \"\",\n",
        "            \"user\": user_tag.text.strip() if user_tag else \"\"\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(items)\n",
        "    raise NotImplementedError(\"TODO: implement q2_parse_items\")\n",
        "\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean numeric fields and fill missing values.\n",
        "    TODO: cast points/comments/rank to int (non-digits -> 0). Fill text fields.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    for col in [\"rank\", \"points\", \"comments\"]:\n",
        "        df[col] = (\n",
        "            df[col]\n",
        "            .astype(str)\n",
        "            .str.extract(r\"(\\d+)\", expand=False)\n",
        "            .fillna(\"0\")\n",
        "            .astype(int)\n",
        "        )\n",
        "\n",
        "    for col in [\"title\", \"link\", \"user\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(\"\").astype(str).str.strip()\n",
        "\n",
        "    return df.reset_index(drop=True)\n",
        "    raise NotImplementedError(\"TODO: implement q2_clean\")\n",
        "\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N. TODO: implement.\"\"\"\n",
        "    return df.sort_values(by=\"points\", ascending=False) \\\n",
        "             .head(top).reset_index(drop=True)\n",
        "    raise NotImplementedError(\"TODO: implement q2_sort_top\")\n"
      ],
      "id": "q2_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q2_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a7a6a3a-752c-4f48-9b04-6f41d8a568fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    rank                                              title  \\\n",
            "0     18                   Solarpunk is happening in Africa   \n",
            "1     29                          End of Japanese community   \n",
            "2     11                             Ratatui – App Showcase   \n",
            "3     24      Dillo, a multi-platform graphical web browser   \n",
            "4     28  ChatGPT terms disallow its use in providing le...   \n",
            "5     27  Firefox profiles: Private, focused spaces for ...   \n",
            "6      7            FBI tries to unmask owner of archive.is   \n",
            "7      5  Open Source Implementation of Apple's Private ...   \n",
            "8      3  Kimi K2 Thinking, a SOTA open-source trillion-...   \n",
            "9     17  Cloudflare Tells U.S. Govt That Foreign Site B...   \n",
            "10     1             ICC ditches Microsoft 365 for openDesk   \n",
            "11    14    Mathematical exploration and discovery at scale   \n",
            "12    23  I may have found a way to spot U.S. at-sea str...   \n",
            "13    22                  How I am deeply integrating Emacs   \n",
            "14    12  Australia has so much solar that it's offering...   \n",
            "\n",
            "                                                 link  points  comments  \\\n",
            "0   https://climatedrift.substack.com/p/why-solarp...    1088       526   \n",
            "1   https://support.mozilla.org/en-US/forums/contr...     849       650   \n",
            "2                   https://ratatui.rs/showcase/apps/     640       187   \n",
            "3              https://github.com/dillo-browser/dillo     416       163   \n",
            "4   https://www.ctvnews.ca/sci-tech/article/openai...     362       399   \n",
            "5   https://blog.mozilla.org/en/firefox/profile-ma...     353       176   \n",
            "6   https://www.heise.de/en/news/Archive-today-FBI...     304       157   \n",
            "7                  https://github.com/openpcc/openpcc     272        51   \n",
            "8   https://moonshotai.github.io/Kimi-K2/thinking....     246        73   \n",
            "9   https://torrentfreak.com/cloudflare-tells-u-s-...     226       131   \n",
            "10  https://www.binnenlandsbestuur.nl/digitaal/int...     215        54   \n",
            "11  https://terrytao.wordpress.com/2025/11/05/math...     184        73   \n",
            "12  https://old.reddit.com/r/OSINT/comments/1opjjy...     180       202   \n",
            "13  https://joshblais.com/blog/how-i-am-deeply-int...     175       114   \n",
            "14  https://electrek.co/2025/11/04/australia-has-s...     162       105   \n",
            "\n",
            "              user  \n",
            "0          JoiDegn  \n",
            "1     phantomathkg  \n",
            "2         AbuAssar  \n",
            "3     nazgulsenpai  \n",
            "4   randycupertino  \n",
            "5        darkwater  \n",
            "6     Projectiboga  \n",
            "7   adam_gyroscope  \n",
            "8        nekofneko  \n",
            "9       iamnothere  \n",
            "10        vincvinc  \n",
            "11          nabla9  \n",
            "12         hentrep  \n",
            "13         signa11  \n",
            "14          ohjeez  \n"
          ]
        }
      ],
      "source": [
        "# Q2 — Write your answer here\n",
        "URL = \"https://news.ycombinator.com/\"\n",
        "\n",
        "html = fetch_html(URL)\n",
        "df_raw = q2_parse_items(html)\n",
        "df_clean = q2_clean(df_raw)\n",
        "\n",
        "df_clean.to_csv(\"data_q2.csv\", index=False)\n",
        "\n",
        "print(q2_sort_top(df_clean, top=15))\n",
        "\n"
      ],
      "id": "q2_skeleton_answer"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxjmiTouckSV"
      },
      "id": "AxjmiTouckSV",
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}